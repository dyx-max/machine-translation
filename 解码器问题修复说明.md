# 解码器问题修复说明

## 关键发现

根据你的测试结果，发现了一个**关键问题**：

1. **纯Transformer基线在当前代码下效果也不好**
2. **第三张图片显示最初用贪心解码的Transformer版本效果逐渐变好**
3. **问题很可能在beam search解码器，而不是GCN**

## 问题分析

### Beam Search可能存在的问题

1. **每次迭代都重新构建邻接矩阵**：
   - 在beam search的每一步，都要为每个候选序列重新构建目标语言邻接矩阵
   - 对于不完整或很短的序列，构建的邻接矩阵可能不准确
   - 这会导致解码过程中的特征分布与训练时不一致

2. **Beam Search复杂度高**：
   - 对于训练初期的模型，beam search可能过于复杂
   - 模型还没有学会正确的翻译模式时，beam search可能会放大错误

3. **贪心解码更适合训练初期**：
   - 简单直接，每一步选择概率最高的token
   - 与训练时的teacher forcing更一致
   - 不会因为beam search的复杂性引入额外误差

## 已完成的修复

### 1. ✅ 实现贪心解码器

**文件**: `utils/decoder.py`

新增 `greedy_decode()` 函数：
- 简单高效，每一步选择概率最高的token
- 生成EOS后立即停止
- 兼容纯Transformer和Transformer+GCN模型

### 2. ✅ 更新验证器支持选择解码方式

**文件**: `training/validator.py`, `training/trainer.py`

- 添加 `decode_method` 参数，支持 "greedy" 或 "beam_search"
- **默认使用贪心解码**（因为效果更好）
- 可以方便地对比两种解码方式的效果

### 3. ✅ 修复Beam Search的EOS处理

**文件**: `utils/decoder.py`

- 改进EOS处理逻辑
- 添加长度归一化
- 但建议在训练初期使用贪心解码

## 使用建议

### 训练初期（推荐使用贪心解码）

```python
# 在trainer.py中，validate()默认使用贪心解码
trainer.validate(epoch)  # 默认使用greedy
```

### 训练后期可以尝试beam search

```python
# 如果模型训练得比较好，可以尝试beam search
trainer.validate(epoch, decode_method="beam_search")
```

### 对比两种解码方式

```python
# 先看贪心解码
trainer.validate(epoch, decode_method="greedy")
# 再看beam search
trainer.validate(epoch, decode_method="beam_search")
```

## 关于GCN的问题

既然纯Transformer在贪心解码下效果逐渐变好，那么：

1. **在贪心解码条件下，加上GCN效果可能会更好**
   - GCN提供了句法信息，应该能帮助翻译
   - 但前提是解码方式正确（贪心解码）

2. **建议测试流程**：
   - 先用纯Transformer + 贪心解码训练，确认效果
   - 然后用Transformer+GCN + 贪心解码训练，对比效果
   - 如果效果好，再尝试beam search

## 预期效果

使用贪心解码后：
- ✅ 输出应该更相关（不再出现完全不相关的长句子）
- ✅ 翻译质量应该逐渐提升（随着训练进行）
- ✅ 输出长度应该更合理（不会过长或过短）

## 下一步

1. **重新训练模型，使用贪心解码验证**
   ```bash
   python train.py  # 默认使用贪心解码验证
   ```

2. **对比纯Transformer和Transformer+GCN**
   ```bash
   python train_baseline.py  # 纯Transformer + 贪心解码
   python train.py           # Transformer+GCN + 贪心解码
   ```

3. **如果效果好，再尝试beam search**
   - 在训练后期（loss较低时）尝试beam search
   - 对比贪心解码和beam search的效果

